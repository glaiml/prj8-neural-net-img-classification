{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/glaiml/prj8-neural-net-img-classification/blob/master/vgk-neuner-img-classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZiQaKY_-gmj",
        "colab_type": "text"
      },
      "source": [
        "# The Real Problem\n",
        "\n",
        "Recognizing multi-digit numbers in photographs captured at street level is an important\n",
        "component of modern-day map making. A classic example of a corpus of such street\n",
        "level photographs is Google’s Street View imagery comprised of hundreds of millions of\n",
        "geo-located 360 degree panoramic images. The ability to automatically transcribe an\n",
        "address number from a geo-located patch of pixels and associate the transcribed\n",
        "number with a known street address helps pinpoint, with a high degree of accuracy, the\n",
        "location of the building it represents.\n",
        "More broadly, recognizing numbers in photographs is a problem of interest to the optical\n",
        "character recognition community. While OCR on constrained domains like document\n",
        "processing is well studied, arbitrary multi-character text recognition in photographs is\n",
        "still highly challenging. This difficulty arises due to the wide variability in the visual\n",
        "appearance of text in the wild on account of a large range of fonts, colors, styles,\n",
        "orientations, and character arrangements. The recognition problem is further\n",
        "complicated by environmental factors such as lighting, shadows, specularities, and\n",
        "occlusions as well as by image acquisition factors such as resolution, motion, and focus\n",
        "blurs.\n",
        "In this project we will use dataset with images centred around a single digit (many of the\n",
        "images do contain some distractors at the sides). Although we are taking a sample of\n",
        "the data which is simpler, it is more complex than MNIST because of the distractors.\n",
        "\n",
        "# Project Description\n",
        "In this hands-on project the goal is to build a python code for image classification from\n",
        "scratch to understand the nitty gritties of building and training a model and further to\n",
        "understand the advantages of neural networks. First we will implement a simple KNN\n",
        "classifier and later implement a Neural Network to classify the images in the SVHN\n",
        "dataset. We will compare the computational efficiency and accuracy between the\n",
        "traditional methods and neural networks.\n",
        "\n",
        "# The Street View House Numbers (SVHN) Dataset\n",
        "SVHN is a real-world image dataset for developing machine learning and object\n",
        "recognition algorithms with minimal requirement on data formatting but comes from a\n",
        "significantly harder, unsolved, real world problem (recognizing digits and numbers in\n",
        "natural scene images). SVHN is obtained from house numbers in Google Street View\n",
        "images.\n",
        "\n",
        "# Overview\n",
        "The images come in two formats as shown below.\n",
        "Format 1 : Original images with character level bounding boxes.\n",
        "Format 2 : MNIST-like 32-by-32 images centered around a single character (many\n",
        "of the images do contain some distractors at the sides).\n",
        "\n",
        "The goal of this project is to take an image from the SVHN dataset and determine what that digit is.\n",
        "This is a multi-class classification problem with 10 classes, one for each digit 0-9. Digit '1' has label 1,\n",
        "'9' has label 9 and '0' has label 10.\n",
        "Although, there are close to 6,00,000 images in this dataset, we have extracted 60,000 images\n",
        "(42000 training and 18000 test images) to do this project. The data comes in a MNIST-like format of\n",
        "32-by-32 RGB images centred around a single digit (many of the images do contain some distractors\n",
        "at the sides).\n",
        "\n",
        "# Reference\n",
        "Acknowledgement for the datasets.\n",
        "Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, Andrew Y. Ng\n",
        "Reading Digits in Natural Images with Unsupervised Feature Learning NIPS Workshop\n",
        "on Deep Learning and Unsupervised Feature Learning 2011. (https://research.google/pubs/pub37648/)\n",
        "\n",
        "http://ufldl.stanford.edu/housenumbers as the URL for this site when necessary\n",
        "\n",
        "# Downloads\n",
        "\n",
        "Refer to Olympus for project related files and instructions.\n",
        "Data Set:\n",
        "● The name of the dataset is SVHN_single_grey1.h5\n",
        "● The data is a subset of the original dataset. Use this subset only for the\n",
        "project.\n",
        "● Keep a copy of your dataset in your own google drive.\n",
        "\n",
        "# Project Objectives\n",
        "The objective of the project is to learn how to implement a simple image classification\n",
        "pipeline based on the k-Nearest Neighbour and a deep neural network.\n",
        "\n",
        "Understand the basic Image Classification pipeline and the data-driven approach (train/predict stages)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_-7CNU7-cuP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjKg-g6_z9nS",
        "colab_type": "code",
        "outputId": "9af28c32-4a57-4f00-8e53-25c9c9edc656",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcGnIhj9AAX2",
        "colab_type": "text"
      },
      "source": [
        "# Data fetching and understand the train/val/test splits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIPmFcLt65co",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "\n",
        "# Open the file as readonly\n",
        "h5f = h5py.File('/content/drive/My Drive/Colab Notebooks/NuNetProject/SVHN_single_grey1.h5', 'r')\n",
        "\n",
        "# Load the training, test and validation set\n",
        "X_train = h5f['X_train'][:]\n",
        "y_train = h5f['y_train'][:]\n",
        "X_test = h5f['X_test'][:]\n",
        "y_test = h5f['y_test'][:]\n",
        "\n",
        "\n",
        "# Close this file\n",
        "h5f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1vwYC23Au-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (X_train.shape)\n",
        "print (y_train.shape)\n",
        "print (X_test.shape)\n",
        "print (y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CSQ2SI7ADvM",
        "colab_type": "text"
      },
      "source": [
        "# Implement and apply an optimal k-Nearest Neighbor (kNN) classifier (7.5 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-yLXPt87ICY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8BTKfTUAJaA",
        "colab_type": "text"
      },
      "source": [
        "# Print the classification metric report (2.5 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7_MslqeAJx2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFKvuLHuAKjR",
        "colab_type": "text"
      },
      "source": [
        "# Implement and apply a deep neural network classifier including (feedforward neural network, RELU activations) (5 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWKs84zHAKqM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_kacYrMAKxh",
        "colab_type": "text"
      },
      "source": [
        "# Understand and be able to implement (vectorized) backpropagation (cost stochastic gradient descent, cross entropy loss, cost functions) (2.5 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fgr8YBVAK4I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_IpfZhnAXwc",
        "colab_type": "text"
      },
      "source": [
        "# Implement batch normalization for training the neural network (2.5 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxo2EgG9ALFC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zEsE_KeAehc",
        "colab_type": "text"
      },
      "source": [
        "# Understand the differences and trade-offs between traditional and NN classifiers with the help of classification metrics (5 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiBiFHMgAgUQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}